{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MATH50003 Numerical Analysis: Problem Sheet 2\n\nThis week we look at other variants of finite-differences, including central differences and second-order\nfinite-differences. We also investigate mathematical properties of dual numbers and extend their implementation to\nother functions. Finally, we see how dual numbers can be combined with Newton iteration for root finding.\n\nQuestions marked with a ⋆ are meant to be completed without using a computer.\n\n## 1. Finite-differences\n\n**Problem 1.1⋆** Use Taylor's theorem to derive an error bound for central differences\n$$\nf'(x) ≈ {f(x + h) - f(x - h) \\over 2h}.\n$$\nFind an error bound when implemented in floating point arithmetic, assuming that\n$$f^{\\rm FP}(x) = f(x) + \\delta_x$$\nwhere $|\\delta_x| \\leq c ϵ_{\\rm m}$.\n\n**SOLUTION**\n\nBy Taylor's theorem, the approximation around $x+h$ is\n$$f(x+h) = f(x) + f'(x)h + \\frac{f''(x)}{2}h^2 + \\frac{f'''(z_1)}{6}h^3,$$\nfor some $z_1 \\in (x, x+h)$ and similarly\n$$f(x-h) = f(x) + f'(x)(-h) + \\frac{f''(x)}{2}h^2 - \\frac{f'''(z_2)}{6}h^3,$$\nfor some $z_2 \\in (x-h, x)$.\n\nSubtracting the second expression from the first we obtain\n$$f(x+h)-f(x-h) = f'(x)(2h) + \\frac{f'''(z_1)+f'''(z_2)}{6}h^3.$$\nHence,\n\n$$f'(x) = \\frac{f(x+h)-f(x-h)}{2h} - \\frac{f'''(z_1)+f'''(z_2)}{12}h^2.$$\n\nThus, the error can be bounded by\n$$\\left|\\frac{f'''(z_1)+f'''(z_2)}{12}h^2\\right|\\le C h^2,$$\nwhere\n$$C=\\max_{y \\in [x-h,x+h]}\\left| \\frac{f'''(y)}{6}\\right|.$$\n\nThe error in floating point arithmetic is\n$$\\left|f'^{FP}(x) - f'(x)\\right| = \\left|\\frac{f^{FP}(x+h)-f^{FP}(x-h)}{2h} - \\frac{f(x+h)-f(x-h)}{2h} +\\frac{f'''(z_1)+f'''(z_2)}{12}h^2\\right|$$\n$$\\le \\left| \\frac{\\delta_{x+h} - \\delta_{x-h}}{2h} \\right| + Ch^2 \\le \\frac{c ϵ_{\\rm m}}{h} + Ch^2.$$\n\n**Problem 1.2** Implement central differences for $f(x) = 1 + x + x^2$ and $g(x) = 1 + x/3 + x^2$. \nPlot the errors for `h = 2.0 .^ (0:-1:-60)` and `h = 10.0 .^ (0:-1:-16)`. \nDerive the error exactly for the different cases to explain the observed behaviour.\n\n**SOLUTION**"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\n\n# define the functions\nf = x -> 1 + x + x^2\ng = x -> 1 + x/3 + x^2\n\n# define analytic first derivatives for comparison\nfp  = x -> 1 + 2 *x\ngp = x ->1/3 + 2 *x\n\n# central difference derivative approximation\ncentraldiff(x, h, f) = (f(x + h) - f(x - h))/(2 *h)\n    \n# computes an error\ncentraldifferror(x, h, f, fp) = abs(centraldiff(x, h, f) - fp(x))\n\n        \n#plotting f and g errors   \nx = 0.0 # some arbitrary point\n\n# helper function to avoid trying to take logs of 0 in plots\nnanabs(x) = iszero(x) ? NaN : abs(x)\n\n# We find the error for the derivative of f is 0 \n# (until we run into the errors for too small h we discussed in the lecture)\nh = 2.0 .^ (0:-1:-60)\nplot(nanabs.(centraldifferror.(x, h, f, fp)), yaxis=:log10, label=\"f\")\nplot!(nanabs.(centraldifferror.(x, h, g, gp)), yaxis=:log10, label=\"g\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "h = 10.0 .^ (0:-1:-16)\nplot(nanabs.(centraldifferror.(x, h, f, fp)), yaxis=:log10, label=\"f\")\nplot!(nanabs.(centraldifferror.(x, h, g, gp)), yaxis=:log10, label=\"g\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute the errors of the central difference approximation of $f'(x)$ we compute\n\n$$\\left| \\frac{f(x+h)-f(x-h)}{2h} - f'(x) \\right|=$$\n$$ =\\left| \\frac{1 + (x+h) + (x+h)^2 - 1 - (x-h) - (x-h)^2}{2h} - (1+2x)\\right|=$$\n$$ =\\left| \\frac{2h + 4hx}{2h} - 1 -2x\\right| = 0.$$\n\nAs we can see, in this case the central difference approximation is exact. The errors we start observing for small step sizes are thus numerical in nature. The values of the function at $f(x+h)$ and $f(x-h)$ eventually become numerically indistinguishable and thus this finite difference approximation to the derivative incorrectly results in $0$.\n\n\nTo compute the errors of the central difference approximation of $g'(x)$ we compute\n\n$$\\left| \\frac{g(x+h)-g(x-h)}{2h} - g'(x) \\right|=$$\n$$ =\\left| \\frac{1 + \\frac{(x+h)}{3} + (x+h)^2 - 1 - \\frac{(x-h)}{3} - (x-h)^2}{2h} - \\left(\\frac{1}{3}+2x \\right)\\right|=$$\n$$ =\\left| \\frac{1}{3} + 2x - \\frac{1}{3} - 2x\\right| = 0.$$\n\n\n\n**Problem 1.3⋆** Use Taylor's theorem to derive an error bound on the second-order derivative approximation\n$$\nf''(x) ≈ {f(x+h) - 2f(x) + f(x-h) \\over h^2}\n$$\nFind an error bound when implemented in floating point arithmetic, assuming that\n$$\nf^{\\rm FP}(x) = f(x) + δ_x\n$$\nwhere $|δ_x| \\leq c ϵ_{\\rm m}$.\n\n**SOLUTION**\n\nUsing the same two formulas as in 1.1 we have\n$$f(x+h) = f(x) + f'(x)h + \\frac{f''(x)}{2}h^2 + \\frac{f'''(z_1)}{6}h^3,$$\nfor some $z_1 \\in (x, x+h)$\nand\n$$f(x-h) = f(x) + f'(x)(-h) + \\frac{f''(x)}{2}h^2 - \\frac{f'''(z_2)}{6}h^3,$$\nfor some $z_2 \\in (x-h, x)$.\n\nSumming the two we obtain\n$$f(x+h) + f(x-h) = 2f(x) + f''(x)h^2 + \\frac{f'''(z_1)}{6}h^3 - \\frac{f'''(z_2)}{6}h^3.$$\n\nThus,\n$$f''(x) = \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} + \\frac{f'''(z_2) - f'''(z_1)}{6}h.$$\n\nHence, the error is \n$$\\left|f''(x) - \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}\\right| = \\left|\\frac{f'''(z_2) - f'''(z_1)}{6}h\\right|\\le 2Ch ,$$\nwhere again\n$$C = \\max_{y\\in[x-h,x+h]}\\left|\\frac{f'''(y)}{6}\\right|.$$\n\nIn floating point arithmetic, the error is\n$$\\left|f''^{FP}(x) - f''(x) \\right|=  \n\\left|\\frac{f^{FP}(x+h) - 2f^{FP}(x) + f^{FP}(x-h)}{h^2} - \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} - \\frac{f'''(z_2) - f'''(z_1)}{6}h\\right|$$\n$$\\le \\left|\\frac{(f^{FP}(x+h) - f(x+h)) - 2(f^{FP}(x)  - f(x)) + (f^{FP}(x-h) - f(x-h))}{h^2}\\right| + \\left|\\frac{f'''(z_2) - f'''(z_1)}{6}h\\right|$$\n$$\\le \\left|\\frac{\\delta_{x+h} - 2\\delta_x + \\delta_{x-h}}{h^2}\\right| + 2Ch \\le \\frac{4cϵ_m}{h^2} + 2Ch.$$\n\n\n**Problem 1.4** Use finite-differences, central differences, and second-order finite-differences to approximate to 5-digits the first and second \nderivatives to the following functions\nat the point $x = 0.1$:\n$$\n\\exp(\\exp x \\cos x + \\sin x), \\prod_{k=1}^{1000} \\left({x \\over k}-1\\right), \\hbox{ and } f^{\\rm s}_{1000}(x)\n$$\nwhere $f^{\\rm s}_n(x)$ corresponds to $n$-terms of the following continued fraction:\n$$\n1 + {x-1 \\over 2 + {x-1 \\over 2 + {x-1 \\over 2 + \\ddots}}},\n$$\ne.g.:\n$$f^{\\rm s}_1(x) = 1 + {x-1 \\over 2}$$\n$$f^{\\rm s}_2(x) = 1 + {x-1 \\over 2 + {x -1 \\over 2}}$$\n$$f^{\\rm s}_3(x) = 1 + {x-1 \\over 2 + {x -1 \\over 2 + {x-1 \\over 2}}}$$\n\n\n**SOLUTION**"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Forward Difference\nforwarddiff(x, h, f) = (f(x + h) - f(x))/h\n\n# We already implemented central differences in a previous problem\n\n# Second derivative via finite difference\nfinitediffsecond(x, h, f) = (f(x + h) - 2 * f(x) + f(x - h))/ (h^2)\n    \n# Define the functions\nf = x -> exp(exp(x)cos(x) + sin(x))\ng = x -> prod([x] ./ (1:1000) .- 1)\nfunction cont(n, x)\n    ret = 2*one(x)\n    for k = 1:n-1\n        ret = 2 + (x-1)/ret\n    end\n    1 + (x-1)/ret\nend\n\n# Choose our point\nx = 0.1;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# We have to be a bit careful with the choice of h\nh = eps()\n# Values for exp(exp(x)cos(x) + sin(x))\nprintln(\"f'($x) with forward difference: \", forwarddiff(x, sqrt(h), f))\nprintln(\"f'($x) with central difference: \", centraldiff(x, cbrt(h), f))\nprintln(\"f''($x) via finite difference:  \", finitediffsecond(x, cbrt(h), f))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Values for prod([x] ./ (1:1000) .- 1)\nprintln(\"f'($x) with forward difference: \", forwarddiff(x, sqrt(h), g))\nprintln(\"f'($x) with central difference: \", centraldiff(x, cbrt(h), g))\nprintln(\"f''($x) via finite difference:  \", finitediffsecond(x, cbrt(h), g))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Values for the continued fraction\nprintln(\"f'($x) with forward difference: \", forwarddiff(x, sqrt(h), x->cont(1000,x)))\nprintln(\"f'($x) with central difference: \", centraldiff(x, sqrt(h), x->cont(1000,x)))\nprintln(\"f''($x) via finite difference:  \", finitediffsecond(x, cbrt(h), x->cont(1000,x)))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dual numbers\n\n**Problem 2.1⋆** \nShow that dual numbers $\\mathbb{D}$ are a _commutative ring_, that is, for all $a,b,c \\in \\mathbb{D}$ the following are satisfied:\n1. _additive associativity_: $(a + b) + c = a + (b + c)$\n2. _additive commutativity_: $a + b = b + a$\n3. _additive identity_: There exists $0 ∈ \\mathbb{D}$ such that $a + 0 = a$.\n4. _additive inverse_: There exists $-a$ such that $(-a) + a = 0$.\n5. _multiplicative associativity_: $(ab)c = a(bc)$\n6. _multiplictive commutativity_: $ab = ba$\n7. _multiplictive identity_: There exists $1 ∈ \\mathbb{D}$ such that $1a= a$.\n8. _distributive_: $a(b+c) = ab + ac$\n\n**SOLUTION**\nIn what follows we write $a = a_r + a_d ϵ$ and likewise for $b,c \\in \\mathbb{D}$.\n\nAdditive associativity and commutativity and existence of additive inverse are both \nimmediate results of dual number addition reducing to element-wise real number addition. \nFurthermore, by definition of addition on $\\mathbb{D}$ the dual number $0+0 ϵ$ acts as the additive \nidentity since\n$$\n(a_r+a_dϵ)+(0+0ϵ) = (a_r+a_dϵ ).\n$$\nWe explicitly prove multiplicative commutativity\n$$\nab = (a_r+a_dϵ )(b_r+b_d ϵ ) = a_r b_r+(a_r b_d+a_d b_r)ϵ = b_r a_r+(b_r a_d+b_d a_r)ϵ = ba.\n$$\nWe also explicitly prove multiplicative associativity:\n$$\n(ab)c = ((a_r b_r+(a_r b_d+a_d b_r) ϵ ) c = \na_r b_r c_r + ((a_r b_d + a_d b_r) c_r  + a_r b_r c_d) ϵ = \na_r b_r c_r + (a_r b_d c_r + a_d b_r c_r  + a_r b_r c_d) ϵ\n$$\nand\n$$\na(bc) = a ((b_r c_r+(b_r c_d+b_d c_r) ϵ ) = a_r b_r c_r + (a_r b_d c_r + a_d b_r c_r  + a_r b_r c_d) ϵ.\n$$\nThe number $1+0ϵ$ serves as the multiplicative identity. Note that for any dual number $a$, we have\n$$\n(1+0ϵ )(a_r + a_d ϵ ) = 1 a_r + (a_r 0 + 1 a_d) ϵ = a_r+a_d ϵ = a.\n$$\nFinally we show distributivity of multiplication:\n$$\na(b+c) = a (b_r+c_r + (b_d+c_d)ϵ) = (a_r b_r + a_r c_r) + (a_r b_d+a_r c_d+ a_d b_r + a_d c_r) ϵ,\n$$\n$$\nab + ac = a_r b_r + (a_d b_r + a_r b_d) ϵ + a_r c_r + (a_d c_r + a_r c_d) ϵ = (a_r b_r + a_r c_r) + (a_r b_d+a_r c_d+ a_d b_r + a_d c_r) ϵ.\n$$\n\n\n**Problem 2.2⋆** A _field_ is a commutative ring such that $0 ≠ 1$ and all nonzero elements have a multiplicative inverse, i.e.,\nthere exists $a^{-1}$ such that $a a^{-1} = 1$. Why isn't $\\mathbb{D}$ a field?\n\n**SOLUTION**\n\nFields require that all nonzero elements have a unique multiplicative inverse. However, this is not the case for dual numbers. To give an explicit counter example, we show that there is no dual number $z$ which is the inverse of $0+ϵ$, i.e. a dual number $z$ such that\n$$\n\\frac{(0+ϵ)}{(z_r+z_d ϵ)} = 1 + 0 ϵ.\n$$\nBy appropriate multiplication with the conjugate we show that\n$$\n\\frac{(0+ϵ)(z_r-z_d ϵ)}{(z_r+z_d ϵ)(z_r-z_d ϵ)} = \\frac{z_r ϵ}{z_r^2} = \\frac{ϵ}{z_r}.\n$$\nThis proves that no choice of real part $z_r$ can reach the multiplicative identity $1+0 ϵ$ when starting from the number $0+ϵ$. More general results for zero real part dual numbers can also be proved.\n \n**Problem 2.3⋆** A _matrix representation_ of a ring are maps from a group/ring to matrices such that matrix addition and multiplication\nbehave exactly like addition and multiplication of the ring. \nThat is, if $A$ and $B$ are elements of the ring and $ρ$ is a representation, then\n$$\nρ(A + B) = ρ(A) + ρ(B) \\hbox{ and } ρ(AB) = ρ(A)ρ(B).\n$$\nShow that the following are matrix representations of complex numbers and dual numbers (respectively):\n$\\rho : a + b {\\rm i} \\mapsto \\begin{pmatrix} a & b \\\\ -b & a \\end{pmatrix},$\n\n$\\rho_ϵ : a + b {\\rm ϵ} \\mapsto \\begin{pmatrix} a & b \\\\ 0 & a \\end{pmatrix}.$\n\n**SOLUTION**\n\nLet $A = a+bi$ and $B=c+di$ and $\\rho$ be the map to their proposed matrix representations. First we check that addition complies with addition of complex numbers, that is \n$(a+bi)+(c+di) = (a+c)+(b+d)i:$\n \n$\\rho(A) + \\rho(B) = \\begin{pmatrix} a & b \\\\ -b & a \\end{pmatrix} + \\begin{pmatrix} c & d \\\\ -d & c \\end{pmatrix} = \\begin{pmatrix} a+c & b+d \\\\ -(b+d) & a+c \\end{pmatrix} = \\rho(A+B).$\n\nNext for multiplication we need $(a+bi)(c+di) = (ac-bd)+(bc+ad)i $:\n\n$\\rho(A)\\rho(B) = \\begin{pmatrix} a & b \\\\ -b & a \\end{pmatrix}\\begin{pmatrix} c & d \\\\ -d & c \\end{pmatrix} = \\begin{pmatrix} ac-bd & bc+ad \\\\ -(bc+ad) & ac-bd \\end{pmatrix} = \\rho(AB)$\n\nNow we move on to dual numbers $A = a+b ϵ $ and $B=c+d ϵ$ and their matrix representation map $\\rho_ϵ$: For addition of dual numbers $(a+bϵ )+(c+dϵ ) = (a+c) + (b+d) ϵ$:\n\n$\\rho_ϵ(A) + \\rho_ϵ(B) = \\begin{pmatrix} a & b \\\\ 0 & a \\end{pmatrix} + \\begin{pmatrix} c & d \\\\ 0 & c \\end{pmatrix} = \\begin{pmatrix} a+c & b+d \\\\ 0 & a+c \\end{pmatrix} = \\rho_ϵ(A+B).$\n\nAnd finally for multiplication of dual numbers $(a+bϵ )(c+dϵ ) = ac+(ad+bc)ϵ$:\n\n$\\rho_ϵ(A)\\rho_ϵ(B) = \\begin{pmatrix}a & b \\\\ 0 & a \\end{pmatrix}\\begin{pmatrix} c & d \\\\ 0 & c \\end{pmatrix} = \\begin{pmatrix} ac & ad+bc \\\\ 0 & ac \\end{pmatrix} = \\rho_ϵ(AB).$\n\n\n**Problem 2.4⋆** What is the correct definition of division on dual numbers, i.e.,\n$$\n(a + b ϵ )/(c + d ϵ ) = s + t ϵ\n$$\nfor what choice of $s$ and $t$? Use dual numbers to compute the derivative of the following functions at $x = 0.1$:\n$$\n\\exp(\\exp x \\cos x + \\sin x), \\prod_{k=1}^3 \\left({x \\over k}-1\\right),\\hbox{ and } f^{\\rm s}_2(x) = {1 + {x - 1 \\over 2 + {x-1 \\over 2}}}\n$$\n\n**SOLUTION**\n\nAs with complex numbers, division is easiest to understand by first multiplying with the conjugate, that is:\n$$\\frac{a+bϵ}{c+dϵ} = \\frac{(a+bϵ)(c-dϵ)}{(c+dϵ)(c-dϵ)}.$$\nExpanding the products and dropping terms with $ϵ^2$ then leaves us with the definition of division for dual numbers (where the denominator must have non-zero real part):\n$$\\frac{a}{c} + \\frac{bc - ad}{c^2}ϵ.$$ Thus we have $s = \\frac{a}{c}$ and $t = \\frac{bc - ad}{c^2}$.\n\nWe saw in the lectures that we have\n$$\n\\exp(a+b ϵ) = \\exp(a)+b \\exp(a) ϵ,\n$$\n$$\n\\sin(a+b ϵ) = \\sin(a)+b \\cos(a) ϵ,\n$$\nand\n$$\n\\cos(a+b ϵ) = \\cos(a)-b \\sin(a) ϵ.\n$$\nUsing these, we find that evaluating $\\exp(\\exp x \\cos x + \\sin x)$ at $a+b ϵ$ yields\n$$\n\\exp ( (\\exp (a) +b \\exp (a) ϵ ) (\\cos(a)-b \\sin(a) ϵ) + \\sin(a)+b \\cos(a) ϵ)\n$$\n$$\n= \\exp ( \\exp (a) \\cos (a) + ( \\cos (a) \\exp (a) - \\sin(a) \\exp (a)) b ϵ + \\sin(a)+b \\cos(a) ϵ) = \\exp ( (\\exp (a) \\cos (a) + \\sin(a)) + b ( \\cos (a) \\exp (a) - \\sin(a) \\exp (a) + \\cos(a)) ϵ )\n$$\nwhich means $\\exp(\\exp x \\cos x + \\sin x)$ evaluated at $a+b ϵ $ is\n$$\n\\exp( (\\exp (a) \\cos (a) + \\sin(a)) ) + b ( \\cos (a) \\exp (a) - \\sin(a) \\exp (a) + \\cos(a)) \\exp( (\\exp (a) \\cos (a) + \\sin(a)) ) ϵ.\n$$\nSetting $b=1$ the derivative at point $a$ is thus given by the dual part, i.e.:\n$$\n( \\cos (a) \\exp (a) - \\sin(a) \\exp (a) + \\cos(a)) \\exp( (\\exp (a) \\cos (a) + \\sin(a)) ).\n$$\n\n**Problem 2.5** Add support for `cos`, `sin`, and `/` to the type `Dual`:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# Dual(a,b) represents a + b*ϵ\nstruct Dual{T}\n    a::T\n    b::T\nend\n\n# Dual(a) represents a + 0*ϵ\nDual(a::Real) = Dual(a, zero(a)) # for real numbers we use a + 0ϵ\n\n# Allow for a + b*ϵ syntax\nconst ϵ = Dual(0, 1)\n\nimport Base: +, *, -, /, ^, zero, exp, cos, sin, one\n\n# support polynomials like 1 + x, x - 1, 2x or x*2 by reducing to Dual\n+(x::Real, y::Dual) = Dual(x) + y\n+(x::Dual, y::Real) = x + Dual(y)\n-(x::Real, y::Dual) = Dual(x) - y\n-(x::Dual, y::Real) = x - Dual(y)\n*(x::Real, y::Dual) = Dual(x) * y\n*(x::Dual, y::Real) = x * Dual(y)\n\n# support x/2 (but not yet division of duals)\n/(x::Dual, k::Real) = Dual(x.a/k, x.b/k)\n\n# a simple recursive function to support x^2, x^3, etc.\nfunction ^(x::Dual, k::Integer)\n    if k < 0\n        error(\"Not implemented\")\n    elseif k == 1\n        x\n    else\n        x^(k-1) * x\n    end\nend\n\n# support identity of type Dual\none(x::Dual) = Dual(one(eltype(x.a)))\n\n# Algebraic operations for duals\n-(x::Dual) = Dual(-x.a, -x.b)\n+(x::Dual, y::Dual) = Dual(x.a + y.a, x.b + y.b)\n-(x::Dual, y::Dual) = Dual(x.a - y.a, x.b - y.b)\n*(x::Dual, y::Dual) = Dual(x.a*y.a, x.a*y.b + x.b*y.a)\n\nexp(x::Dual) = Dual(exp(x.a), exp(x.a) * x.b)\n\nfunction cos(x::Dual)\n    # TODO: implement cos for Duals\nend\n\nfunction sin(x::Dual)\n    # TODO: implement sin for Duals\nend\n\nfunction /(x::Dual, y::Dual)\n    # TODO: implement division for Duals\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION**"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "cos(x::Dual) = Dual(cos(x.a), -sin(x.a) * x.b)\n\nsin(x::Dual) = Dual(sin(x.a), cos(x.a) * x.b)\n\nfunction /(x::Dual, y::Dual)\n    if iszero(y.a)\n        error(\"Division for dual numbers is ill-defined when denonimator real part is zero.\")\n    end\n    return Dual(x.a / y.a, (y.a*x.b - x.a*y.b)/y.a^2)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2.6** Use dual numbers to compute the derivatives to\n$$\n\\exp(\\exp x \\cos x + \\sin x), \\prod_{k=1}^{1000} \\left({x \\over k}-1\\right), \\hbox{ and } f^{\\rm s}_{1000}(x).\n$$\nDoes your answer match (to 5 digits) Problem 1.4?\n\n**SOLUTION**\n\nWith the previous problems solved, this is as simple as running"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "fdual = f(0.1+ϵ)\nfdual.b"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "gdual = g(0.1+ϵ)\ngdual.b"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "contdual = cont(1000,0.1+ϵ)\ncontdual.b"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Newton iteration\n\nNewton iteration is an algorithm for computed roots of a function $f$ using its derivative: given an initial guess $x_0$, one\nobtains a sequence of guesses via\n$$\nx_{k+1} = x_k - {f(x_k) \\over f'(x_k)}\n$$\n\n**Problem 3.1** Use `Dual` to implement the following function which returns $x_n$:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function newton(f, x0, n)\n    ## TODO: compute x_n \nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION**"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function newton(f, x0, n)\n    xk = x0\n    for k = 1:n\n        fd = f(xk+ϵ)\n        xk = xk - fd.a/fd.b\n    end\n    return xk\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a simple test case for the above function:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# example\nf_ex(x) = x^2-3\nn = 5\nx0 = 1\n# compute proposed root\nxn = newton(f_ex,x0,n) \n# check that obtained point is an approximate root\nf_ex(xn)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3.2** Compute points $y$ such that $|f(y)| \\leq 10^{-13}$ (i.e., approximate roots):\n$$\n\\exp(\\exp x \\cos x + \\sin x)-6\\hbox{ and } \\prod_{k=1}^{1000} \\left({x \\over k}-1\\right) - {1 \\over 2}\n$$\n(Hint: you may need to try different `x0` and `n` to get convergence. Plotting the function should give an\nindication of a good initial guess.)\n\n**SOLUTION**\n\nWe can plot the functions on a few ranges to get an intuition"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\n\nf1(x) = exp(exp(x)*cos(x) + sin(x)) - 6\nf2(x) = prod([x] ./ range(1,1000) .- 1) - 1/2\n\nplot(f1,-2,2,color=\"blue\")\nplot!(x->0,color=\"red\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(f2,0,2,color=\"blue\")\nplot!(x->0,color=\"red\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then use our Newton iteration to compute approximate roots"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "rootf1 = newton(f1, 1.5, 5)\nf1(rootf1)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "rootf2 = newton(f2, 0.3, 8)\nf2(rootf2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3.3** Compute points $y$ such that $|f^{\\rm s}_{1000}(y) - j| \\leq 10^{-13}$ for $j = 1,2,3$. \nMake a conjecture of what $f^{\\rm s}_n(x)$ converges to as $n → ∞$. (Bonus problem: Prove your conjecture.)\n\n**SOLUTION**"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "xn = newton(x->cont(1000,x)-1.,0.5,10)\ncont(1000,xn)-1."
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "xn = newton(x->cont(1000,x)-2.,0.5,10)\ncont(1000,xn)-2."
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "xn = newton(x->cont(1000,x)-3.,0.5,10)\ncont(1000,xn)-3."
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "By plotting the function we can conjecture that the continued fraction converges to $\\sqrt{x}$:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\nplot(x->cont(1000,x),0,10)\nplot!(x->sqrt(x))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a handful of ways to prove this conjecture. Here is one - start with\n\n$$ \\sqrt{x}(1+\\sqrt{x}) = \\sqrt{x}+x,$$\n\nthen extend the RHS by $0 = +1-1$ to also obtain the factor $1+\\sqrt{x}$ there, resulting in\n\n$$ \\sqrt{x}(1+\\sqrt{x}) = (1+\\sqrt{x})+x-1.$$\n\nDividing through $(1+\\sqrt{x})$ now yields\n\n$$ \\sqrt{x} = 1 + \\frac{x-1}{1+\\sqrt{x}}.$$\n\nNote that we can now plug this equation into itself on the right hand side to obtain a recursive continued fraction for the square root function."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.7.0"
    },
    "kernelspec": {
      "name": "julia-1.7",
      "display_name": "Julia 1.7.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
