# MATH50003 Numerical Analysis: Problem Sheet 5

This problem sheet explores positive definite matrices,
Cholesky decompositions, matrix norms, and the singular value decomposition.

Questions marked with a ‚ãÜ are meant to be completed without using a computer.

```julia
using LinearAlgebra, Plots
```

## 1. Positive definite matrices and Cholesky decompositions


**Problem 1.1‚ãÜ** Use the Cholesky decomposition to determine
which of the following matrices are symmetric positive definite:
$$
\begin{bmatrix} 1 & -1  \\
-1 & 3
\end{bmatrix}, \begin{bmatrix} 1 & 2 & 2  \\
2 & 1 & 2\\
2 & 2 & 1
\end{bmatrix}, \begin{bmatrix} 3 & 2 & 1  \\
2 & 4 & 2\\
1 & 2 & 5
\end{bmatrix}, 
\begin{bmatrix} 4 & 2 & 2 & 1  \\
2 & 4 & 2 & 2\\
2 & 2 & 4 & 2 \\
1 & 2 & 2 & 4
\end{bmatrix}
$$

**Problem 1.2‚ãÜ** Recall that an inner product $‚ü®ùê±, ùê≤‚ü©$ on $‚Ñù^n$
over the reals $‚Ñù$ satisfies, for all $ùê±,ùê≤,ùê≥ ‚àà ‚Ñù$ and $a,b ‚àà ‚Ñù$:
1. Symmetry: $‚ü®ùê±, ùê≤‚ü© = ‚ü®ùê≤, ùê±‚ü©$
2. Linearity: $‚ü®aùê±+bùê≤, ùê≥‚ü© = a ‚ü®ùê±, ùê≥‚ü©+ b‚ü®ùê≤, ùê≥‚ü©$
3. Posive-definite: $‚ü®ùê±, ùê±‚ü© > 0$
Prove that $‚ü®ùê±, ùê≤‚ü©$ is an inner product if and only if
$$
‚ü®ùê±, ùê≤‚ü© = ùê±^‚ä§ K ùê≤
$$
where $K$ is a symmetric positive definite matrix.


**Problem 1.3‚ãÜ** Show that a matrix is symmetric positive definite if and only if it has a Cholesky
decomposition of the form
$$
A = U U^‚ä§
$$
where $U$ is upper triangular with positive entries on the diagonal.


**Problem 1.4‚ãÜ** Prove that the following $n √ó n$ matrix is symmetric positive definite
for any $n$:
$$
Œî_n := \begin{bmatrix}
2 & -1 \\
-1 & 2 & -1 \\
& -1 & 2 & ‚ã± \\
&& ‚ã± & ‚ã± & -1 \\
&&& -1 & 2
\end{bmatrix}
$$
Deduce its two Cholesky decompositions: $Œî_n = L_n L_n^‚ä§ = U_n U_n^‚ä§$ where
$L_n$ is lower triangular and $U_n$ is upper triangular.

**Problem 1.4** `SymTridiagonal(dv, eu)` is a type for representing symmetric tridiagonal
matrices (that is, `SymTridiagonal(dv, ev) == Tridiagonal(ev, dv, ev)`). Complete the following
implementation of `cholesky` to return a `Bidiagonal` cholesky factor in $O(n)$ operations, 
and check your result
compared to your solution of Problem 1.3 for `n = 1_000_000`.
```julia
using LinearAlgebra
import LinearAlgebra: cholesky

# return a Bidiagonal L such that L'L == A (up to machine precision)
cholesky(A::SymTridiagonal) = cholesky!(copy(A))

# return a Bidiagonal L such that L'L == A (up to machine precision)
# You are allowed to change A
function cholesky!(A::SymTridiagonal)
    d = A.dv # diagonal entries of A
    u = A.ev # sub/super-diagonal entries of A
    T = float(eltype(A)) # return type, make float in case A has Ints
    n = length(d)
    ld = zeros(T, n) # diagonal entries of L
    ll = zeros(T, n-1) # sub-diagonal entries of L

    # TODO: populate ld and ll

    Bidiagonal(ld, l, :L)
end
```



## 2. Matrix norms

**Problem 2.1‚ãÜ** Prove the following:
$$
\begin{align*}
\|A\|_‚àû &= \max_k \|A[k,:]\|_1 \\
\|A\|_{1 ‚Üí ‚àû} &= \|\hbox{vec}(A)\|_‚àû = \max_{kj} |a_{kj}|
\end{align*}
$$

**Problem 2.2‚ãÜ** For a rank-1 matrix $A = ùê± ùê≤^‚ä§$ prove that
$$
\|A \|_2 = \|ùê±\|_2 \|ùê≤\|_2.
$$

**Problem 2.3‚ãÜ** Show for any orthogonal matrix $Q ‚àà ‚Ñù^m$ and
matrix $A ‚àà ‚Ñù^{m √ó n}$ that
$$
\|Q A\|_F = \|A\|_F
$$
by first showing that $\|A \|_F = \sqrt{\hbox{tr}(A^‚ä§ A)}$ using the
_trace_ of an $m √ó m$ matrix:
$$
\hbox{tr}(A) = a_{11} + a_{22} + ‚ãØ + a_{mm}.
$$


## 3. Singular value decomposition

**Problem 3.1‚ãÜ** Show that $\|A \|_2 ‚â§ \|A\|_F ‚â§¬†\sqrt{r} \|A \|_2$ where
$r$ is the rank of $A$.

**SOLUTION**

From Problem 2.3 use the fact that $\|A \|_F = \sqrt{\hbox{tr}(A^‚ä§ A)}$, where $A\in \mathbb{R}^{m\times n}$.

Hence,

$$\|A \|_F^2 = \hbox{tr}(A^‚ä§ A) = \sigma_1^2 +...+\sigma_m^2$$

where $\sigma_1\ge...\ge \sigma_n \ge 0$ are the singular values of $A$ and $\sigma_i^2$ are the eigenvalues of $A^T A$

Knowing that $\|A\|_2^2 = \sigma_1^2$ we have $\|A \|_2^2 ‚â§ \|A\|_F^2$

Moreover, since if the rank of $A$ is $r$ we have that $\sigma_{r+1}=...=\sigma_m=0$ and we also know $\sigma_1\ge...\ge \sigma_n \ge 0$, we have that

$\|A\|_F^2 = \sigma_1^2 +...+\sigma_m^2 =\sigma_1^2 +...+\sigma_r^2 \le r \sigma_1^2 =r \|A \|_2^2$

Hence,

$\|A \|_2 ‚â§ \|A\|_F ‚â§¬†\sqrt{r} \|A \|_2$

**Problem 3.2** Consider functions sampled on a $(n+1) √ó (n+1)$ 2D grid 
$(x_k,y_j) = (k/n, j/n)$ where $k,j = 0,‚Ä¶,n$. 
For $n = 100$, what is the lowest rank $r$ such that
the  best rank-$r$ approximation to the samples 
that is accurate to within $10^{-5}$ accuracy for the following functions:
$$
(x + 2y)^2, \cos(\sin x {\rm e}^y), 1/(x + y + 1), \hbox{sign}(x-y)
$$
For which examples does the answer change when $n = 1000$?

**SOLUTION**

```julia
#define functions
f‚ÇÅ(x,y) = (x + 2 * y) ^ 2
f‚ÇÇ(x,y) = cos(sin(x)*exp(y))
f‚ÇÉ(x,y) = 1/(x + y + 1)
f‚ÇÑ(x,y) = sign(x-y)

#define n and error goal
error = 1e-5

#helper function to compute nxn samples
function samples(f, n)
    x = y = range(0, 1; length=n)
    return f.(x,y')
end

#find minimum rank of f with precision œµ
function find_min_rank(f, n, œµ)
    œÉ = svdvals(samples(f, n))
    for i in 1:length(œÉ)
        if sum(œÉ[i:end]) <= œµ
            return i-1
        end
    end
    return length(œÉ)
end


n=100
println("Error ‚â§ ", error, " with n = ", n)
println("Rank for f‚ÇÅ = ", find_min_rank(f‚ÇÅ, n, error))
println("Rank for f‚ÇÇ = ", find_min_rank(f‚ÇÇ, n, error))
println("Rank for f‚ÇÉ = ", find_min_rank(f‚ÇÉ, n, error))
println("Rank for f‚ÇÑ = ", find_min_rank(f‚ÇÑ, n, error))


n=1000
println("Error ‚â§ ", error, " with n = ", n)
println("Rank for f‚ÇÅ = ", find_min_rank(f‚ÇÅ, n, error))
println("Rank for f‚ÇÇ = ", find_min_rank(f‚ÇÇ, n, error))
println("Rank for f‚ÇÉ = ", find_min_rank(f‚ÇÉ, n, error))
println("Rank for f‚ÇÑ = ", find_min_rank(f‚ÇÑ, n, error))
```

**Problem 3.3‚ãÜ** Define the _pseudo-inverse_:
$$
A^+ := V Œ£^{-1} U^‚ä§.
$$
Show that it satisfies the _Moore-Penrose conditions_:
1. $A A^+ A = A$
2. $A^+ A A^+ = A^+$
3. $(A A^+)^‚ä§  = A A^+$ and $(A^+ A)^‚ä§ = A^+ A$

**SOLUTION**

Let $A=U\Sigma V^T$ and $A^+ := V Œ£^{-1} U^‚ä§$. Note that $UU^T = U^TU = I$ ($U$ orthonormal) and $V^T V =I$

1. We have
$$A A^+ A = U \Sigma V^T V \Sigma^{-1} U^T U \Sigma V^T = U \Sigma \Sigma^{-1} \Sigma V^T = U\Sigma V^T = A$$

2. Moreover,
$$A^+ A A^+ = V \Sigma^{-1}U^T U \Sigma V^T V \Sigma^{-1} U^T = V \Sigma^{-1}\Sigma \Sigma^{-1} U^T = V \Sigma^{-1} U^T = A^+$$


3. Furthermore, $AA^+ = U \Sigma V^T V \Sigma^{-1} U^T = U U^T = I$, thus

$$(AA^+)^T = I^T = I = AA^+$$

Moreover, $A^+A = V \Sigma^{-1} U^T U \Sigma V^T = VV^T$, hence,

$$(A^+A)^T = (VV^T)^T=VV^T=A^+A$$

**Problem 3.4‚ãÜ** Show for $A ‚àà ‚Ñù^{m √ó n}$ with $m ‚â• n$ and full rank
that $ùê± =  A^+ ùêõ$ is the least squares solution, i.e., minimises $\| A ùê± - ùêõ \|_2$.

**SOLUTION**

If $x=A^+b$ then

$$\| Ax - b \|_2 = \| A A^+b - b\|_2 = \|b-b\|_2=\|0\|_2=0,$$

so $x$ minimises the norm.

**Problem 3.5‚ãÜ**
If $A ‚àà ‚Ñù^{m √ó n}$ has a non-empty kernel there are multiple solutions to the least
squares problem as 
we can add any element of the kernel. Show that $ùê± = A^+ ùêõ$ gives the least squares solution
such that $\| ùê± \|_2$ is minimised.

**SOLUTION**
